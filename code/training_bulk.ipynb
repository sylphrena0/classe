{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Superconductivity Regression Notebook**\n",
    "Trains models to predict critical temperatures based on features found with \"*../code/get_featurizers.ipynb*\". Imports data from \"*../data/supercon_feat.csv*\", which is produced in *get_featurizers.ipynb*. The orginal data is from the supercon database. This notebook is to produce results in a graphical format, in bulk\n",
    "\n",
    "*Author: Kirk Kleinsasser*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(300000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "#dill.load_session('../data/latest-run.db') #this can load a saved python session so I don't need to rerun computationally expensive cells\n",
    "%autosave 300 \n",
    "#autosaves code every five minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add MAE metric. Do SVR optimization. Redo extratrees optimzation with just n_est. Try RFR more. Try Superlearner more. Elbow method for kmeans.\n",
    "\n",
    "#TODO: maybe do comparision of params vs scores\n",
    "#physics-informed ML \n",
    "#lolopy - uncertainty, at least for RFR\n",
    "#citrine informatics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries / Define Import Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general imports:\n",
    "import warnings #to suppress grid search warnings\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns #heatmaps\n",
    "\n",
    "#regression models:\n",
    "from mlens.ensemble import SuperLearner\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#various ML tools:\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, r2_score, mean_absolute_error, mean_squared_error\n",
    "from skopt import BayesSearchCV #bayesian optimization\n",
    "\n",
    "#imports the data from get_featurizers. Function because some models we may want infinity:\n",
    "def import_data(replace_inf=False):\n",
    "    global data, target, train_data, test_data, train_target, test_target #variables that we want to define globally (outside of this funtion)\n",
    "    data = pd.DataFrame(pd.read_csv('../data/supercon_features.csv')) #loads data produced in get_featurizer.ipynb\n",
    "    target = data.pop('Tc') #remove target (critical temp) from data\n",
    "\n",
    "    if replace_inf: #replaces values of infinity with NaN if replace_inf is True\n",
    "        data.replace([np.inf, -np.inf], np.nan, inplace=True) \n",
    "\n",
    "    #TODO: debug feaurizers - NaN is entered when there is an error in the featurizer\n",
    "    data.drop(['name','Unnamed: 0', 'composition'], axis=1, inplace=True) #drop columns irrelevant to training\n",
    "    data = data[data.columns[data.notnull().any()]] #drop columns that are entirely NaN (12 columns) \n",
    "\n",
    "    for col in data: #replaces NaN with zeros\n",
    "        data[col] = pd.to_numeric(data[col], errors ='coerce').fillna(0).astype('float')\n",
    "\n",
    "    #creates a test train split, with shuffle and random state for reproducibility \n",
    "    train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=0.15, random_state=43, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions\n",
    "To train models and return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one(model_name, regressor, parameters): #define function that trains a model and prints scores and plots\n",
    "    global train_data, train_data, test_data, test_target #we need these variables and don't want to pass them as arguments\n",
    "    with plt.rc_context({'xtick.color':'white', 'ytick.color':'white','axes.titlecolor':'white','figure.facecolor':'#1e1e1e','text.color':'white','legend.labelcolor':'black'}):\n",
    "        plt.title(f\"{model_name} - Prediction vs. Actual Value (CV)\", color='white')\n",
    "        model = regressor(**parameters) #unpacks model and params\n",
    "        model.fit(train_data.values, train_target.values) #fit the model\n",
    "        model_pred = model.predict(test_data) #make predictions on test data\n",
    "\n",
    "        mse = round(mean_squared_error(test_target, model_pred),3) #find mean square error\n",
    "        r_squared = round(r2_score(test_target, model_pred),3) #find r2 score\n",
    "\n",
    "        #make our plot - with plt.rc_context sets theme to look good in dark mode\n",
    "        difference = np.abs(test_target - model_pred) #function that finds the absolute difference between predicted and actual value\n",
    "        im = plt.scatter(model_pred, test_target, cmap='plasma_r', norm=plt.Normalize(0, 120), c=difference, label=\"Critical Temperature (K)\") #create scatter plot of data \n",
    "        plt.plot((0,135), (0,135), 'k--', alpha=0.75) #add expected line. Values must be changed with different data to look good\n",
    "        plt.title(model_name, c='white')\n",
    "        plt.ylabel('Prediction', c='white')\n",
    "        plt.xlabel('Actual Value', c='white')\n",
    "        plt.annotate(f'MSE: {mse}', xy = (1.0, -0.15), xycoords='axes fraction', ha='right', va=\"center\", fontsize=10) #add footnote with MSE\n",
    "        plt.annotate(f'MAE: {mse}', xy = (0.41, -0.15), xycoords='axes fraction', ha='center', va=\"center\", fontsize=10) #add footnote with MSE\n",
    "        plt.annotate(f'R2: {r_squared}', xy = (0.18, -0.15), xycoords='axes fraction', ha='right', va=\"center\", fontsize=10) #add footnote with R2 \n",
    "        plt.legend()\n",
    "        plt.colorbar().set_label(label=\"Difference from Actual (K)\", color='white') #using .set_label() as colorbar() does accept color arguments\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(models, title): #define function that trains up to eight models at once plots with each model in a subplot. Includes model scores\n",
    "    global train_data, train_data, test_data, test_target #we need these variables and don't want to pass them as arguments\n",
    "    import_data(replace_inf=True)\n",
    "    with plt.rc_context({'xtick.color':'white', 'ytick.color':'white','axes.titlecolor':'white','figure.facecolor':'#1e1e1e','text.color':'white','legend.labelcolor':'black'}):\n",
    "        fig, ax = plt.subplots(2, 4, sharex='col', sharey='row', figsize=(28,10))\n",
    "        fig.subplots_adjust(hspace=0.35)\n",
    "        fig.suptitle(title, color='white', size=16)\n",
    "        for [model_name, regressor, parameters, ax1, ax2] in models:\n",
    "            model = regressor(**parameters) #unpacks model and params\n",
    "            model.fit(train_data, train_target) #fit the model\n",
    "            model_pred = model.predict(test_data) #make predictions on test data\n",
    "\n",
    "            mse = round(mean_squared_error(test_target, model_pred),3) #find mean square error\n",
    "            r_squared = round(r2_score(test_target, model_pred),3) #find r2 score\n",
    "\n",
    "            #make our plot - with plt.rc_context sets theme to look good in dark mode\n",
    "            difference = np.abs(test_target - model_pred) #function that finds the absolute difference between predicted and actual value\n",
    "            im = ax[ax1, ax2].scatter(model_pred, test_target, cmap='plasma_r', norm=plt.Normalize(0, 120), c=difference, label=\"Critical Temperature (K)\") #create scatter plot of data \n",
    "            ax[ax1, ax2].plot((0,135), (0,135), 'k--', alpha=0.75) #add expected line. Values must be changed with different data to look good\n",
    "            ax[ax1, ax2].set_title(model_name, c='white')\n",
    "            ax[ax1, ax2].set_xlabel('Prediction', c='white')\n",
    "            ax[ax1, ax2].set_ylabel('Actual Value', c='white')\n",
    "            ax[ax1, ax2].annotate(f'MSE: {mse}', xy = (1.0, -0.15), xycoords='axes fraction', ha='right', va=\"center\", fontsize=10) #add footnote with MSE\n",
    "            ax[ax1, ax2].annotate(f'MAE: {mse}', xy = (0.41, -0.15), xycoords='axes fraction', ha='center', va=\"center\", fontsize=10) #add footnote with MAE\n",
    "            ax[ax1, ax2].annotate(f'R2: {r_squared}', xy = (0.18, -0.15), xycoords='axes fraction', ha='right', va=\"center\", fontsize=10) #add footnote with R2 \n",
    "\n",
    "        handles, labels = ax[0,0].get_legend_handles_labels()\n",
    "        fig.legend(handles=handles,loc='lower center')\n",
    "\n",
    "        fig.colorbar(im, ax=ax.ravel().tolist()).set_label(label=\"Difference from Actual (K)\", color='white') #using .set_label() as colorbar() does accept color arguments\n",
    "        \n",
    "        plt.savefig('../data/results.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "models =   [[\"Support Vector Machines (Linear)\", SVR, {}, 0, 0],\n",
    "            [\"Random Forest Regression\", RandomForestRegressor, {}, 1, 0],\n",
    "            [\"Support Vector Machines (Poly)\", SVR, {}, 0, 1],\n",
    "            [\"KNeighbors Regression\", KNeighborsRegressor, {}, 1, 1],\n",
    "            [\"Decision Tree Regression\", DecisionTreeRegressor, {}, 0, 2],\n",
    "            [\"Extra Trees Regression\", ExtraTreesRegressor, {}, 1, 2],\n",
    "            [\"Elastic Net Regression\", ElasticNet, {}, 0, 3],\n",
    "            [\"Bayesian Regression\", BayesianRidge, {}, 1, 3]]\n",
    "evaluate(models, \"Prediction vs. Actual Value (CV) - Unoptimized\") #call evaluation function, defined in ./project_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models =   [[\"Support Vector Machines\", SVR, {C=1, epsilon=10, gamma='auto', kernel='linear', random_state=43}, 0, 0],\n",
    "            [\"Random Forest Regression\", RandomForestRegressor, {}, 1, 0],\n",
    "            [\"\", , {}, 0, 1],\n",
    "            [\"KNeighbors Regression\", KNeighborsRegressor, {metric='manhattan', n_jobs=-1, n_neighbors=5}, 1, 1],\n",
    "            [\"Decision Tree Regression\", DecisionTreeRegressor, {criterion='poisson', max_features=0.5, random_state=43}, 0, 2],\n",
    "            [\"Extra Trees Regression\", ExtraTreesRegressor, {}, 1, 2],\n",
    "            [\"Elastic Net Regression\", ElasticNet, {alpha=1e-05, l1_ratio=0.0}, 0, 3],\n",
    "            [\"Bayesian Regression\", BayesianRidge, {}, 1, 3]]\n",
    "evaluate(models, \"Prediction vs. Actual Value (CV) - Optimized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of base-models for superlearner\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(SVR())\n",
    "\t# models.append(SVR())\n",
    "\tmodels.append(ElasticNet(alpha=1e-05, l1_ratio=0.0))\n",
    "\tmodels.append(DecisionTreeRegressor())\n",
    "\tmodels.append(RandomForestRegressor())\n",
    "\tmodels.append(KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=5))\n",
    "\t# models.append(ExtraTreesRegressor())\n",
    "\t# models.append(SGDRegressor(alpha=1000.0, loss='epsilon_insensitive', max_iter=1500, penalty='l1'))\n",
    "\t# models.append(BayesianRidge(alpha_init=1.2, lambda_init=0.0001))\n",
    "\n",
    "\treturn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_super_learner(X):\n",
    "\tensemble = SuperLearner(scorer=r2_score, folds=10, shuffle=True, sample_size=len(X), random_state=43)\n",
    "\t# add base models\n",
    "\tmodels = get_models()\n",
    "\tensemble.add(models)\n",
    "\t# add the meta model\n",
    "\tensemble.add_meta(LinearRegression())\n",
    "\n",
    "\treturn ensemble\n",
    "ensemble = get_super_learner(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dill.dump_session('../data/supercon_ml_latest_run.db') #this can dump a python session so I can resume later, after restarts and such"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CLASSE')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cd1206b64939dd3f6b0a0731e141469e9fe64d6063519119675fbaf8ff2b829"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
